{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f24167",
   "metadata": {},
   "source": [
    "# BoTNeTIoT-L01 Review\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c58d9f",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e06d51f-3d50-43fb-8820-4447dc2742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew\n",
    "from scipy.fft import fft\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb69678",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92406fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2426574, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>MI_dir_L0.1_mean</th>\n",
       "      <th>MI_dir_L0.1_variance</th>\n",
       "      <th>H_L0.1_weight</th>\n",
       "      <th>H_L0.1_mean</th>\n",
       "      <th>H_L0.1_variance</th>\n",
       "      <th>HH_L0.1_weight</th>\n",
       "      <th>HH_L0.1_mean</th>\n",
       "      <th>HH_L0.1_std</th>\n",
       "      <th>...</th>\n",
       "      <th>HH_jit_L0.1_mean</th>\n",
       "      <th>HH_jit_L0.1_variance</th>\n",
       "      <th>HpHp_L0.1_weight</th>\n",
       "      <th>HpHp_L0.1_mean</th>\n",
       "      <th>HpHp_L0.1_std</th>\n",
       "      <th>HpHp_L0.1_magnitude</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505914e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.931640</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.818989e-12</td>\n",
       "      <td>1.931640</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.818989e-12</td>\n",
       "      <td>1.93164</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.348699e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.263102e+08</td>\n",
       "      <td>5.662344e+17</td>\n",
       "      <td>1.93164</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>138.592929</td>\n",
       "      <td>1.818989e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.904273</td>\n",
       "      <td>86.981750</td>\n",
       "      <td>2.311822e+02</td>\n",
       "      <td>2.904273</td>\n",
       "      <td>86.981750</td>\n",
       "      <td>2.311822e+02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505914e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.856432</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.902546</td>\n",
       "      <td>83.655268</td>\n",
       "      <td>2.040614e+02</td>\n",
       "      <td>3.902546</td>\n",
       "      <td>83.655268</td>\n",
       "      <td>2.040614e+02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505914e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.902545</td>\n",
       "      <td>81.685828</td>\n",
       "      <td>1.775746e+02</td>\n",
       "      <td>4.902545</td>\n",
       "      <td>81.685828</td>\n",
       "      <td>1.775746e+02</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.529571e+08</td>\n",
       "      <td>5.669445e+17</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  MI_dir_L0.1_weight  MI_dir_L0.1_mean  MI_dir_L0.1_variance  \\\n",
       "0           0            1.000000         98.000000          0.000000e+00   \n",
       "1           1            1.931640         98.000000          1.818989e-12   \n",
       "2           2            2.904273         86.981750          2.311822e+02   \n",
       "3           3            3.902546         83.655268          2.040614e+02   \n",
       "4           4            4.902545         81.685828          1.775746e+02   \n",
       "\n",
       "   H_L0.1_weight  H_L0.1_mean  H_L0.1_variance  HH_L0.1_weight  HH_L0.1_mean  \\\n",
       "0       1.000000    98.000000     0.000000e+00         1.00000          98.0   \n",
       "1       1.931640    98.000000     1.818989e-12         1.93164          98.0   \n",
       "2       2.904273    86.981750     2.311822e+02         1.00000          66.0   \n",
       "3       3.902546    83.655268     2.040614e+02         1.00000          74.0   \n",
       "4       4.902545    81.685828     1.775746e+02         2.00000          74.0   \n",
       "\n",
       "    HH_L0.1_std  ...  HH_jit_L0.1_mean  HH_jit_L0.1_variance  \\\n",
       "0  0.000000e+00  ...      1.505914e+09          0.000000e+00   \n",
       "1  1.348699e-06  ...      7.263102e+08          5.662344e+17   \n",
       "2  0.000000e+00  ...      1.505914e+09          0.000000e+00   \n",
       "3  0.000000e+00  ...      1.505914e+09          0.000000e+00   \n",
       "4  9.536743e-07  ...      7.529571e+08          5.669445e+17   \n",
       "\n",
       "   HpHp_L0.1_weight  HpHp_L0.1_mean  HpHp_L0.1_std  HpHp_L0.1_magnitude  \\\n",
       "0           1.00000            98.0       0.000000            98.000000   \n",
       "1           1.93164            98.0       0.000001           138.592929   \n",
       "2           1.00000            66.0       0.000000           114.856432   \n",
       "3           1.00000            74.0       0.000000            74.000000   \n",
       "4           1.00000            74.0       0.000000            74.000000   \n",
       "\n",
       "   HpHp_L0.1_radius  HpHp_L0.1_covariance  HpHp_L0.1_pcc  label  \n",
       "0      0.000000e+00                   0.0            0.0      0  \n",
       "1      1.818989e-12                   0.0            0.0      0  \n",
       "2      0.000000e+00                   0.0            0.0      0  \n",
       "3      0.000000e+00                   0.0            0.0      0  \n",
       "4      0.000000e+00                   0.0            0.0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./team_11_BotNeTIoT-L01_label_NoDuplicates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba5805",
   "metadata": {},
   "source": [
    "# Data Cleaning & Handling Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27c896",
   "metadata": {},
   "source": [
    "## Check missing values and drop if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6a379-ede9-4523-baaa-44611071766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Data Cleaning & Handling Imbalance\n",
    "\n",
    "print(f\"Total null values: {df.isnull().sum().sum()}\\n\")\n",
    "\n",
    "# Drop duplicates if any\n",
    "df = df.drop_duplicates()\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.apply(lambda x : np.round(x, 5))\n",
    "\n",
    "df_attack = df[df['label'] == 0]   # attack\n",
    "df_benign = df[df['label'] == 1]   # benign\n",
    "\n",
    "\n",
    "df_attack_downsampled = resample(\n",
    "    df_attack,\n",
    "    replace=False,\n",
    "    n_samples=len(df_benign),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_balanced = pd.concat([df_attack_downsampled, df_benign])\n",
    "df_balanced = df_balanced.reset_index()\n",
    "print(f\"Total value count:\\n\\n{df_balanced['label'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dad3e",
   "metadata": {},
   "source": [
    "## Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea25ef0-15b2-417f-9e8c-d92bfa6870cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window statistics\n",
    "window_size = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb0226",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53109424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.iloc[:, :-1].rolling(window=window_size).mean().apply(lambda x: np.round(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6946501",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f18c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.iloc[:, :-1].rolling(window=window_size).var().apply(lambda x: np.round(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83715f31",
   "metadata": {},
   "source": [
    "### Skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.iloc[:, :-1].rolling(window=window_size).skew().apply(lambda x: np.round(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df65787",
   "metadata": {},
   "source": [
    "## Time-Series Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_avg = df_balanced.iloc[:, :-1].rolling(window=10).mean().mean(axis=1)\n",
    "sliding_avg.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa325c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sliding_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c9b59-c981-42b3-b7d2-8848c03584d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window averages\n",
    "\n",
    "\n",
    "# Frequency domain (FFT magnitude of first feature as example)\n",
    "sample_signal = df_balanced.iloc[:, 0].values[:512]   # take first 512 samples\n",
    "fft_features = np.abs(fft(sample_signal))\n",
    "plt.plot(fft_features[:50])\n",
    "plt.title(\"Frequency Domain Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb03fc1",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c9bd5d-834f-44da-b971-7664fc59f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_balanced.drop(columns=['label']))\n",
    "y = df_balanced['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec198d",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1411c-04ce-42a3-846a-e635e7bacd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of benign vs attack per device (if device column exists)\n",
    "if 'device' in df_balanced.columns:\n",
    "    device_profiles = df_balanced.groupby(['device', 'label']).size().unstack(fill_value=0)\n",
    "    device_profiles['benign_attack_ratio'] = device_profiles['Benign'] / (device_profiles.sum(axis=1))\n",
    "    print(device_profiles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266aea24",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22137ea-97c0-414a-af39-5fdbba513b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure X is DataFrame\n",
    "X_orig = pd.DataFrame(X)\n",
    "\n",
    "# Reset indices to avoid mismatch\n",
    "X = X_orig.reset_index(drop=True)\n",
    "y = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df_xy = pd.concat([X, y.rename(\"label\")], axis=1)\n",
    "\n",
    "# Drop rows with NaN across all columns (features + label)\n",
    "df_xy = df_xy.dropna()\n",
    "\n",
    "# Split back into X and y\n",
    "X_clean = df_xy.drop(columns=['label'])\n",
    "y_clean = df_xy['label']\n",
    "\n",
    "\n",
    "# Build pipeline for PCA\n",
    "pca_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),  # handles any remaining NaN\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=2))\n",
    "])\n",
    "\n",
    "# Fit + transform\n",
    "X_pca = pca_pipeline.fit_transform(X_clean)\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y_clean, palette=\"Set1\", alpha=0.6)\n",
    "plt.title(\"PCA Scatterplot (with NaN handling and aligned labels)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70321234",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bef296",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223694d-2b73-4840-a0c3-adcbc22797d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "sns.heatmap(pd.DataFrame(X).corr(), cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.xticks(list(range(0,len(df_balanced.columns))),df_balanced.columns)\n",
    "plt.yticks(list(range(0,len(df_balanced.columns))),df_balanced.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a915dea",
   "metadata": {},
   "source": [
    "## Summary Before vs. After Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d20155-4e8f-4b7a-97a3-a34ea6aca2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Feature Shape:\", df.shape)\n",
    "print(\"Engineered Feature Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3ad2f",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58d1f7",
   "metadata": {},
   "source": [
    "### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(X).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0664e2",
   "metadata": {},
   "source": [
    "After feature engineering and normalization, the dataset contains 1,026,994 samples with 28 features.\n",
    "\n",
    "The mean of each feature is close to 0, and the standard deviation is approximately 1, confirming that z-score normalization was applied successfully.\n",
    "\n",
    "Minimum and maximum values typically range between -8 and +8, indicating that outliers exist but are bounded within a normalized scale.\n",
    "\n",
    "The quartiles (25%, 50%, 75%) are centered around 0, showing the data is well-distributed after scaling.\n",
    "\n",
    "Compared to the raw dataset , the engineered dataset ensures fair comparability across all traffic features, which is crucial for PCA and classification.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
