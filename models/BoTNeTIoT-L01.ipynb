{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# BoTNeTIoT-L01 Review\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.fft import fft\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./datasets/BotNeTIoT-L01_label_NoDuplicates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Data Cleaning & Handling Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Check missing values and drop if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Data Cleaning & Handling Imbalance\n",
    "\n",
    "print(f\"Total null values: {df.isnull().sum().sum()}\\n\")\n",
    "\n",
    "# Drop duplicates if any\n",
    "df = df.drop_duplicates()\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.apply(lambda x : np.round(x, 5))\n",
    "\n",
    "df_attack = df[df['label'] == 0]   # attack\n",
    "df_benign = df[df['label'] == 1]   # benign\n",
    "\n",
    "\n",
    "df_attack_downsampled = resample(\n",
    "    df_attack,\n",
    "    replace=False,\n",
    "    n_samples=len(df_benign),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_balanced = pd.concat([df_attack_downsampled, df_benign])\n",
    "df_balanced = df_balanced.reset_index()\n",
    "print(f\"Total value count:\\n\\n{df_balanced['label'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window statistics\n",
    "window_size = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.iloc[:, :-1].rolling(window=window_size).mean().apply(lambda x: np.round(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.iloc[:, :-1].rolling(window=window_size).var().apply(lambda x: np.round(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.iloc[:, :-1].rolling(window=window_size).skew().apply(lambda x: np.round(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Time-Series Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_avg = df_balanced.iloc[:, :-1].rolling(window=10).mean().mean(axis=1)\n",
    "sliding_avg.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sliding_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window averages\n",
    "\n",
    "\n",
    "# Frequency domain (FFT magnitude of first feature as example)\n",
    "sample_signal = df_balanced.iloc[:, 0].values[:512]   # take first 512 samples\n",
    "fft_features = np.abs(fft(sample_signal))\n",
    "plt.plot(fft_features[:50])\n",
    "plt.title(\"Frequency Domain Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_balanced.drop(columns=['label']))\n",
    "y = df_balanced['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of benign vs attack per device (if device column exists)\n",
    "if 'device' in df_balanced.columns:\n",
    "    device_profiles = df_balanced.groupby(['device', 'label']).size().unstack(fill_value=0)\n",
    "    device_profiles['benign_attack_ratio'] = device_profiles['Benign'] / (device_profiles.sum(axis=1))\n",
    "    print(device_profiles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure X is DataFrame\n",
    "X_orig = pd.DataFrame(X)\n",
    "\n",
    "# Reset indices to avoid mismatch\n",
    "X = X_orig.reset_index(drop=True)\n",
    "y = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df_xy = pd.concat([X, y.rename(\"label\")], axis=1)\n",
    "\n",
    "# Drop rows with NaN across all columns (features + label)\n",
    "df_xy = df_xy.dropna()\n",
    "\n",
    "# Split back into X and y\n",
    "X_clean = df_xy.drop(columns=['label'])\n",
    "y_clean = df_xy['label']\n",
    "\n",
    "\n",
    "# Build pipeline for PCA\n",
    "pca_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),  # handles any remaining NaN\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=2))\n",
    "])\n",
    "\n",
    "# Fit + transform\n",
    "X_pca = pca_pipeline.fit_transform(X_clean)\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y_clean, palette=\"Set1\", alpha=0.6)\n",
    "plt.title(\"PCA Scatterplot (with NaN handling and aligned labels)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "sns.heatmap(pd.DataFrame(X).corr(), cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.xticks(list(range(0,len(df_balanced.columns))),df_balanced.columns)\n",
    "plt.yticks(list(range(0,len(df_balanced.columns))),df_balanced.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Summary Before vs. After Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Feature Shape:\", df.shape)\n",
    "print(\"Engineered Feature Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(X).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "After feature engineering and normalization, the dataset contains 1,026,994 samples with 28 features.\n",
    "\n",
    "The mean of each feature is close to 0, and the standard deviation is approximately 1, confirming that z-score normalization was applied successfully.\n",
    "\n",
    "Minimum and maximum values typically range between -8 and +8, indicating that outliers exist but are bounded within a normalized scale.\n",
    "\n",
    "The quartiles (25%, 50%, 75%) are centered around 0, showing the data is well-distributed after scaling.\n",
    "\n",
    "Compared to the raw dataset , the engineered dataset ensures fair comparability across all traffic features, which is crucial for PCA and classification.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
