{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Creating Clean TON_IoT Data\n",
    "Source: https://research.unsw.edu.au/projects/toniot-datasets (See TON_IoT datasets/Processed_datasets/Processed_Network_dataset)\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "**This Python notebook is only for generating data from the raw datasets.**\n",
    "\n",
    "\n",
    "The pre-generated file (team_11_TON_IoT_unsw_edu_au_cleaned.csv), is already available in Step1-Datasets-Feature-Engineering.\n",
    "\n",
    "If you simply want to use the data, use the team11_TON_IoT data.\n",
    "\n",
    "If you wish to change the data cleaning parameters, this is the right place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "current_working_directory = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Read datasets\n",
    "\n",
    "When exporting is complete, please delete the Processed_Network_dataset folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "ds_array = []\n",
    "for i in range(1, 24):\n",
    "    try:\n",
    "        ds_array.append(pd.read_csv(f\"./raw/Processed_Network_dataset/Network_dataset_{i}.csv\"))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"To run this notebook, extract the and move the 'Processed_Network_dataset' folder of Processed Network dataset.zip to '{current_working_directory}/raw'.\")\n",
    "        print(\"The notebook will now raise an error.\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Analyzing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## What's included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to see available types\n",
    "what_i_use = []\n",
    "for i in range(0, 23):\n",
    "    for e in ds_array[i][\"type\"].unique():\n",
    "        if e not in what_i_use:\n",
    "            what_i_use.append(e)\n",
    "print(f\"What the data finds: {what_i_use}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print counts per type\n",
    "for i in range(0, 23):\n",
    "    print(f\"Spreadsheet {i+1}\") \n",
    "    print(ds_array[i][\"type\"].value_counts(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Removing unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "for i in range(0, 23):\n",
    "    ds_array[i] = ds_array[i].drop(columns=[\n",
    "        \"service\",\"dns_query\", \"dns_AA\", \n",
    "        \"dns_RD\", \"dns_RA\", \"dns_rejected\", \n",
    "        \"ssl_version\", \"ssl_cipher\", \"ssl_resumed\", \n",
    "        \"ssl_established\", \"ssl_subject\", \"ssl_issuer\", \n",
    "        \"http_trans_depth\", \"http_method\", \"http_uri\", \n",
    "        \"http_version\", \"http_request_body_len\", \"http_response_body_len\", \n",
    "        \"http_status_code\", \"http_user_agent\", \"http_orig_mime_types\", \n",
    "        \"http_resp_mime_types\", \"weird_name\", \"weird_addl\", \n",
    "        \"weird_notice\", \"dns_qclass\",\n",
    "        \"dns_qtype\", \"dns_rcode\", \"http_referrer\", ])\n",
    "    if \"uid\" in ds_array[i]:\n",
    "        ds_array[i] = ds_array[i].drop(columns=[\"uid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Drop specific attack types: \n",
    "* password\n",
    "* xss\n",
    "* ransomware\n",
    "* backdoor\n",
    "* injection\n",
    "* mitm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-network based attacks\n",
    "for i in range(0, 23):\n",
    "    ds_array[i]= ds_array[i][ds_array[i][\"type\"] != \"password\"]\n",
    "    ds_array[i]= ds_array[i][ds_array[i][\"type\"] != \"xss\"]\n",
    "    ds_array[i]= ds_array[i][ds_array[i][\"type\"] != \"ransomware\"]\n",
    "    ds_array[i]= ds_array[i][ds_array[i][\"type\"] != \"backdoor\"]\n",
    "    ds_array[i]= ds_array[i][ds_array[i][\"type\"] != \"injection\"]\n",
    "    ds_array[i]= ds_array[i][ds_array[i][\"type\"] != \"mitm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### If you wish to see the individual cleaned CSV files:\n",
    "change the following line to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_INDIVIDUAL_CSV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see above\n",
    "if EXPORT_INDIVIDUAL_CSV == True:\n",
    "    for i in range(0, 23):\n",
    "        ds_array[i].to_csv(f\"./team_11_individual_TON_IoT_unsw_edu_au_{i+1}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Reduce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "newDS  = pd.concat(ds_array, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Correct data error with src_bytes\n",
    "For some packets, src_bytes becomes 0.0.0.0, which is fixed by setting to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_error = newDS[newDS['src_bytes'] == \"0.0.0.0\"]\n",
    "newDS.loc[ip_error.index,\"src_bytes\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Drop unneeded scanning entries\n",
    "Decided by taking a fraction close to, but less than the amount of 'normal' entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNING_ENTRIES = 649106\n",
    "D_DOS_ENTRIES = 474231\n",
    "DOS_ENTRIES = 421916"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Drop unneeded scanning entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = newDS[newDS[\"type\"] == \"scanning\"]\n",
    "temp = temp.reset_index()\n",
    "# from the end of the data capture and up\n",
    "newDS = newDS.drop(index=list(temp[-(len(temp)- SCANNING_ENTRIES):][\"index\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Drop unneeded DDoS entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = newDS[newDS[\"type\"] == \"ddos\"]\n",
    "temp = temp.reset_index()\n",
    "# from the end of the data capture and up\n",
    "newDS = newDS.drop(index=list(temp[-(len(temp)- D_DOS_ENTRIES):][\"index\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Drop unneeded DoS entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = newDS[newDS[\"type\"] == \"dos\"]\n",
    "temp = temp.reset_index()\n",
    "# from the end of the data capture and up\n",
    "newDS = newDS.drop(index=list(temp[-(len(temp)- DOS_ENTRIES):][\"index\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDS[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDS.to_csv(\"../Step1-Datasets-Feature-Engineering/team11_TON_IoT_unsw_edu_au_cleaned.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
